\chapter{PROGRAM OPERASI PENJUMLAHAN MATRIKS}
\label{appx:addition}
% \section{Kode untuk dijalankan di GPU}\label{kode_potential_cpp}

\section{\emph{Module}}

\begin{lstlisting}
using CUDA
using DataFrames
using Statistics
\end{lstlisting}

\section{Untuk dijalankan di GPU}

\begin{lstlisting}
function operation_cuda(A, B)
    C = CUDA.zeros(Float16, size(A))
    CUDA.@sync C .= A .+ B
    return C
end

function simulate_gpu(A_normal, B_normal)
    # Convert your Float64 matrices to Float32 and then to CuArray{Float32}
    A = CUDA.convert(CuArray{Float16}, A_normal)
    B = CUDA.convert(CuArray{Float16}, B_normal)
    # Mengukur waktu eksekusi
    cuda_start = CUDA.@elapsed result_gpu = operation_cuda(A, B)
    return cuda_start
end
\end{lstlisting}

\section{Untuk dijalankan di CPU}

\begin{lstlisting}
function operation_cpu(A, B)
    C = zeros(Float16, size(A))
    C .= A .+ B
    return C
end

function simulate_cpu(A_normal, B_normal)
    normal_start = @elapsed result_cpu = operation_cpu(A_normal, B_normal)
    return normal_start
end
\end{lstlisting}

\section{Simulasi}

\begin{lstlisting}
function simulate(N::Int64, n_loop::Int64)
    println("Total size: $(N*N)")
    results_gpu = []
    results_cpu = []
    for i in 1:n_loop
        A_normal = rand(Float16, N, N)
        B_normal = rand(Float16, N, N)
        benchmark_gpu = simulate_gpu(A_normal, B_normal)
        benchmark_cpu = simulate_cpu(A_normal, B_normal)
        push!(results_gpu, benchmark_gpu)
        push!(results_cpu, benchmark_cpu)
    end
    println("Mean CPU: $(mean(results_cpu))")
    println("Mean GPU: $(mean(results_gpu))")
    return DataFrame(CPU=results_cpu, GPU=results_gpu)
end
\end{lstlisting}

\chapter{PROGRAM OPERASI PENGURANGAN MATRIKS}
\label{appx:substraction}

\section{\emph{Module}}

\begin{lstlisting}
using CUDA
using DataFrames
using Statistics
\end{lstlisting}

\section{Untuk dijalankan di GPU}

\begin{lstlisting}
function operation_cuda(A, B)
    C = CUDA.zeros(Float16, size(A))
    CUDA.@sync C .= A .- B
    return C
end

function simulate_gpu(A_normal, B_normal)
    # Convert your Float64 matrices to Float32 and then to CuArray{Float32}
    A = CUDA.convert(CuArray{Float16}, A_normal)
    B = CUDA.convert(CuArray{Float16}, B_normal)
    # Mengukur waktu eksekusi
    cuda_start = CUDA.@elapsed result_gpu = operation_cuda(A, B)
    return cuda_start
end
\end{lstlisting}

\section{Untuk dijalankan di CPU}

\begin{lstlisting}
function operation_cpu(A, B)
    C = zeros(Float16, size(A))
    C .= A .- B
    return C
end

function simulate_cpu(A_normal, B_normal)
    normal_start = @elapsed result_cpu = operation_cpu(A_normal, B_normal)
    return normal_start
end
\end{lstlisting}

\section{Simulasi}

\begin{lstlisting}
function simulate(N::Int64, n_loop::Int64)
    println("Total size: $(N*N)")
    results_gpu = []
    results_cpu = []
    for i in 1:n_loop
        A_normal = rand(Float16, N, N)
        B_normal = rand(Float16, N, N)
        benchmark_gpu = simulate_gpu(A_normal, B_normal)
        benchmark_cpu = simulate_cpu(A_normal, B_normal)
        push!(results_gpu, benchmark_gpu)
        push!(results_cpu, benchmark_cpu)
    end
    println("Mean CPU: $(mean(results_cpu))")
    println("Mean GPU: $(mean(results_gpu))")
    return DataFrame(CPU=results_cpu, GPU=results_gpu)
end
\end{lstlisting}

\chapter{PROGRAM OPERASI PERKALIAN SKALAR DENGAN MATRIKS}
\label{appx:multiplication_scalar_matrix}

\section{\emph{Module}}

\begin{lstlisting}
using CUDA
using DataFrames
using Statistics
\end{lstlisting}

\section{Untuk dijalankan di GPU}

\begin{lstlisting}
function operation_gpu(A, skalar)
    C = CUDA.zeros(Float32, size(A))
    CUDA.@sync C = A * skalar
    return C
end

function simulate_gpu(A_normal, skalar_normal)
    A = CUDA.convert(CuArray{Float32}, A_normal)
    cuda_start = CUDA.@elapsed result_gpu = operation_gpu(A, skalar_normal)
    return cuda_start
end
\end{lstlisting}

\section{Untuk dijalankan di CPU}

\begin{lstlisting}
function operation_cpu(A, skalar)
    C = zeros(Float32, size(A))
    C = A * skalar
    return C
end

function simulate_cpu(A_normal, skalar)
    normal_start = @elapsed result_cpu = operation_cpu(A_normal, skalar)
    return normal_start
end
\end{lstlisting}

\section{Simulasi}

\begin{lstlisting}
function simulate(N::Int64, n_loop::Int64)
    println("Total size: $(N*N)")
    results_gpu = []
    results_cpu = []
    for i in 1:n_loop
        A_normal = rand(Float32, N, N)
        scalar_normal = rand(Float32)  # Generate a random scalar
        benchmark_gpu = simulate_gpu(A_normal, scalar_normal)
        benchmark_cpu = simulate_cpu(A_normal, scalar_normal)
        push!(results_gpu, benchmark_gpu)
        push!(results_cpu, benchmark_cpu)
    end
    println("Mean CPU: $(mean(results_cpu))")
    println("Mean GPU: $(mean(results_gpu))")
    return DataFrame(CPU=results_cpu, GPU=results_gpu)
end
\end{lstlisting}

\chapter{PROGRAM OPERASI PERKALIAN ANTAR MATRIKS}
\label{appx:multiplication_matrix_matrix}

\section{\emph{Module}}

\begin{lstlisting}
using CUDA
using DataFrames
using Statistics
\end{lstlisting}

\section{Untuk dijalankan di GPU}

\begin{lstlisting}
function operation_gpu(A, B)
    C = CUDA.zeros(Float32, size(A))
    CUDA.@sync C = A * B
    return C
end

function simulate_gpu(A_normal, B_normal)
    A = CUDA.convert(CuArray{Float32}, A_normal)
    B = CUDA.convert(CuArray{Float32}, B_normal)
    cuda_start = CUDA.@elapsed result_gpu = operation_gpu(A, B)
    return cuda_start
end
\end{lstlisting}

\section{Untuk dijalankan di CPU}

\begin{lstlisting}
function operation_cpu(A, B)
    C = zeros(Float32, size(A))
    C = A * B
    return C
end

function simulate_cpu(A_normal, B_normal)
    normal_start = @elapsed result_cpu = operation_cpu(A_normal, B_normal)
    return normal_start
end
\end{lstlisting}

\section{Simulasi}

\begin{lstlisting}
function simulate(N::Int64, n_loop::Int64)
    println("Total size: $(N*N)")
    results_gpu = []
    results_cpu = []
    for i in 1:n_loop
        A_normal = rand(Float32, N, N)
        B_normal = rand(Float32, N, N)
        benchmark_gpu = simulate_gpu(A_normal, B_normal)
        benchmark_cpu = simulate_cpu(A_normal, B_normal)
        push!(results_gpu, benchmark_gpu)
        push!(results_cpu, benchmark_cpu)
    end
    println("Mean CPU: $(mean(results_cpu))")
    println("Mean GPU: $(mean(results_gpu))")
    return DataFrame(CPU=results_cpu, GPU=results_gpu)
end
\end{lstlisting}


\chapter{PROGRAM OPERASI INVERSE MATRIKS}
\label{appx:inverse}

\section{\emph{Module}}

\begin{lstlisting}
using CUDA
using DataFrames
using Statistics
\end{lstlisting}

\section{Untuk dijalankan di GPU}

\begin{lstlisting}
function operation_matrices_cuda(gpu_matrix)
    inverted_gpu_matrix = inv(gpu_matrix)  
    return inverted_gpu_matrix  
end

function simulate_gpu(A_normal)
    A = CUDA.cu(A_normal)  
    result_gpu, cuda_start = CUDA.@timed operation_matrices_cuda(A)
    return cuda_start 
end
\end{lstlisting}

\section{Untuk dijalankan di CPU}

\begin{lstlisting}
function operation_matrices_normal(A)
    C = zeros(Float32, size(A))
    C = inv(A)
    return C
end

function simulate_cpu(A_normal)
    normal_start = @elapsed result_cpu = operation_matrices_normal(A_normal)
    return normal_start
end
\end{lstlisting}

\section{Simulasi}

\begin{lstlisting}
function simulate(N::Int64, n_loop::Int64)
    results_gpu = []
    results_cpu = []
    for i in 1:n_loop
        A_normal = rand(Float32, N, N)
        benchmark_gpu = simulate_gpu(A_normal)
        benchmark_cpu = simulate_cpu(A_normal)
        push!(results_gpu, benchmark_gpu)
        push!(results_cpu, benchmark_cpu)
    end
    println("Mean CPU: $(mean(results_cpu))")
    println("Mean GPU: $(mean(results_gpu))")
    return DataFrame(CPU=results_cpu, GPU=results_gpu)
end
\end{lstlisting}

\chapter{PROGRAM PENCARIAN NILAI EIGEN}
\label{appx:eigenvalue}

\section{\emph{Module}}

\begin{lstlisting}
using LinearAlgebra
using SparseArrays
using CUDA
using Statistics
using DataFrames
\end{lstlisting}

\section{Fungsi pembuat matriks persamaan schrodinger melalui pendekatan beda-hingga}

\begin{lstlisting}
function build_matrix(n::Int)
    dx = 2.0f0 / n  # Menggunakan literal Float32
    gamma = 50.0f0  # Menggunakan literal Float32
    b = (gamma * dx) ^ 2
    y = LinRange(-2.0f0, 2.0f0, n)  # Memastikan y adalah Float32

    main_diag = fill(2.0f0, n)  # Isi dengan Float32
    off_diag = fill(-1.0f0, n-1)  # Isi dengan Float32
    a_sparse = spdiagm(0 => main_diag, 1 => off_diag, -1 => off_diag)

    # Penyesuaian elemen diagonal berdasarkan y
    for j in 1:n
        if y[j] <= -1.0 || y[j] >= 1.0
            a_sparse[j, j] += b
        end
    end

    return Matrix{Float32}(a_sparse)  # Konversi eksplisit matriks ke Float32
end
\end{lstlisting}

\section{Untuk dijalankan di GPU}

\begin{lstlisting}
function simulate_gpu(A)
    gpu_start = CUDA.@elapsed begin
        eigenvalues, eigenvectors = CUDA.@sync eigen(A)
        idx = sortperm(eigenvalues)
        eigenvalues = eigenvalues[idx]
        eigenvectors = eigenvectors[:, idx]
    end
    return gpu_start
end
\end{lstlisting}

\section{Untuk dijalankan di CPU}

\begin{lstlisting}
function simulate_cpu(A)
    cpu_start = @elapsed begin
        eigenvalues, eigenvectors = eigen(A)
        idx = sortperm(eigenvalues)
        eigenvalues = eigenvalues[idx]
        eigenvectors = eigenvectors[:, idx]
    end

    return cpu_start
end
\end{lstlisting}

\section{Simulasi}

\begin{lstlisting}
function simulate(n::Int, n_loop::Int)
    println("Matrix size: $n x $n")
    results_gpu = Float32[]
    results_cpu = Float32[]

    A_cpu = build_matrix(n)
    A_gpu = CuArray(A_cpu)

    for _ in 1:n_loop
        benchmark_gpu = simulate_gpu(A_gpu)
        benchmark_cpu = simulate_cpu(A_cpu)
        push!(results_gpu, benchmark_gpu)
        push!(results_cpu, benchmark_cpu)
    end

    println("Mean CPU: $(mean(results_cpu))")
    println("Mean GPU: $(mean(results_gpu))")
    return DataFrame(CPU=results_cpu, GPU=results_gpu)
end
\end{lstlisting}

\chapter{PROGRAM VALIDASI NILAI EIGEN}
\label{appx:eigenvalue_validation}

\section{\emph{Module}}

\begin{lstlisting}
using LinearAlgebra
using SparseArrays
using Plots
using CUDA
using Statistics
using Plots
using DataFrames
\end{lstlisting}

\section{Konstanta dan Fungsi Pembantu}

\subsection{Konstanta}

\begin{lstlisting}
hbar = 1.0545718e-34  # Konstanta Planck tereduksi (Joule sekon)
m = 9.10938356e-31    # Massa elektron (kg)
L = 2.0               # Panjang sumur potensial dalam meter
\end{lstlisting}

\subsection{Fungsi Pembantu}

\begin{lstlisting}
# Untuk mendapatkan nilai analitik nya
function analytics_eigenvalues(n::Int)
    return (n^2 * pi^2 * hbar^2) / (2 * m * L^2)
end

# Untuk mengonversi dari nilai eigen ke bentuk energi
function convert_eigenvalue_to_energy(n::Int64, eigenvalue::Float32)
    return (hbar^2 * eigenvalue) / (2 * m * ((L/n)^2))
end
\end{lstlisting}

\section{Fungsi pembuat matriks persamaan schrodinger melalui pendekatan beda-hingga}

\begin{lstlisting}
function build_matrix(n::Int)
    dx = 2.0f0 / n  # Menggunakan literal Float32
    y = LinRange(-2.0f0, 2.0f0, n)  # Memastikan y adalah Float32

    main_diag = fill(2.0f0, n)  # Isi dengan Float32
    off_diag = fill(-1.0f0, n-1)  # Isi dengan Float32
    a_sparse = spdiagm(0 => main_diag, 1 => off_diag, -1 => off_diag)

    return Matrix{Float32}(a_sparse)  # Konversi eksplisit matriks ke Float32
end
\end{lstlisting}

\section{Untuk dijalankan di GPU}

\begin{lstlisting}
function solve_gpu(A)
    eigenvalues, eigenvectors = CUDA.@sync eigen(A)
    idx = sortperm(eigenvalues)
    eigenvalues = eigenvalues[idx]
    eigenvectors = eigenvectors[:, idx]
    return Array(eigenvalues), Array(eigenvectors)
end
\end{lstlisting}

\section{Untuk dijalankan di CPU}

\begin{lstlisting}
function solve_cpu(A)
    eigenvalues, eigenvectors = eigen(A)
    idx = sortperm(eigenvalues)
    eigenvalues = eigenvalues[idx]
    eigenvectors = eigenvectors[:, idx]
    return eigenvalues, eigenvectors
end
\end{lstlisting}

\section{Simulasi}

\begin{lstlisting}
function simulate(n::Int)
    A_cpu = build_matrix(n)
    A_gpu = CuArray(A_cpu)
    eigenvalues_gpu, eigenvectors_gpu = solve_gpu(A_gpu)
    eigenvalues_cpu, eigenvectors_cpu = solve_gpu(A_gpu)

    return DataFrame(
        CPU=convert_eigenvalue_to_energy.(n, eigenvalues_cpu[1:10]), 
        GPU=convert_eigenvalue_to_energy.(n, eigenvalues_gpu[1:10]), 
        analitik=eigenvalues_analytics[1:10], 
        perbedaan=((abs.(convert_eigenvalue_to_energy.(n, eigenvalues_cpu[1:10]) .- eigenvalues_analytics[1:10])) ./ eigenvalues_analytics[1:10]) .* 100
        )
end
\end{lstlisting}
