@book{strogatz_2020_infinite,
  author = {Strogatz, Steven},
  publisher = {Mariner Books},
  title = {INFINITE POWERS : how calculus reveals the secrets of the universe.},
  year = {2020}
}

@book{boas_2006_mathematical,
  author = {Boas, Mary L},
  publisher = {John Wiley & Sons},
  title = {Mathematical Methods in the Physical Sciences},
  year = {2006}
}

@article{zbay_2021_poisson,
  author = {Özbay, Ali Girayhan and Hamzehloo, Arash and Laizet, Sylvain and Tzirakis, Panagiotis and Rizos, Georgios and Schuller, Björn},
  title = {Poisson CNN: Convolutional neural networks for the solution of the Poisson equation on a Cartesian mesh},
  doi = {10.1017/dce.2021.7},
  urldate = {2023-01-11},
  volume = {2},
  year = {2021},
  journal = {Data-Centric Engineering}
}

@article{samuel_1959_some,
  author = {Samuel, A. L.},
  month = {07},
  pages = {210-229},
  title = {Some Studies in Machine Learning Using the Game of Checkers},
  doi = {10.1147/rd.33.0210},
  urldate = {2023-02-23},
  volume = {3},
  year = {1959},
  journal = {IBM Journal of Research and Development}
}

@book{bayen_2020_python,
  author = {Bayen, Timmy},
  publisher = {Elsevier Academic Press},
  title = {PYTHON PROGRAMMING AND NUMERICAL METHODS : a Guide for Engineers and scientists.},
  url = {https://pythonnumericalmethods.berkeley.edu/notebooks/Index.html},
  urldate = {2023-02-23},
  year = {2020}
}

@book{stewart_2020_calculus,
  author = {Stewart, James},
  edition = {2},
  publisher = {Cengage Learning},
  title = {CALCULUS : early transcendentals.},
  year = {2020}
}

@book{riley_2006_mathematical,
  author = {Riley, K F and Hobson, M P and Bence, S J},
  month = {03},
  publisher = {Cambridge University Press},
  title = {Mathematical Methods for Physics and Engineering},
  year = {2006}
}

@book{gleick_2015_chaos,
  author = {Gleick, James},
  publisher = {The Folio Society},
  title = {Chaos : making a new science},
  year = {2015}
}

@book{griffiths_2011_introduction,
  author = {Griffiths, David J},
  publisher = {Wiley-Vch},
  title = {Introduction to Elementary Particles},
  year = {2011}
}

@article{shan_2020_study,
  author = {Shan, Tao and Tang, Wei and Dang, Xunwang and Li, Maokun and Yang, Fan and Xu, Shenheng and Wu, Ji},
  month = {09},
  pages = {6725-6733},
  title = {Study on a Fast Solver for Poisson’s Equation Based on Deep Learning Technique},
  doi = {10.1109/tap.2020.2985172},
  urldate = {2023-03-15},
  volume = {68},
  year = {2020},
  journal = {IEEE Transactions on Antennas and Propagation}
}

@article{lee_1977_classical,
  author = {Lee, K. K.},
  month = {01},
  pages = {169-170},
  title = {Classical Electrodynamics 2nd Ed. (John David Jackson)},
  doi = {10.1137/1019029},
  urldate = {2020-05-19},
  volume = {19},
  year = {1977},
  journal = {SIAM Review}
}

@book{robertalexanderadams_2014_calculus,
  author = {Robert Alexander Adams and Essex, Christopher and Pearson, },
  publisher = {Pearson, Copyright},
  title = {Calculus : a complete course},
  year = {2014}
}

@misc{herman_2021_21,
  author = {Herman, Russel},
  month = {11},
  title = {2.1: Introduction},
  url = {https://math.libretexts.org/Bookshelves/Differential_Equations/Introduction_to_Partial_Differential_Equations_(Herman)/023A_Second_Order_Partial_Differential_Equations/2.013A_Introduction},
  urldate = {2023-03-16},
  year = {2021},
  organization = {Mathematics LibreTexts}
}

@book{yehudapinchover_2013_an,
  author = {Yehuda Pinchover and Rubinstein, Jacob},
  publisher = {Cambridge University Press},
  title = {An introduction to partial differential equations},
  year = {2013}
}

@book{arfken_2013_mathematical,
  author = {Arfken, George B and Weber, Hans J and Harris, Frank E},
  publisher = {Amsterdam (Holanda) Elsevier},
  title = {Mathematical methods for physicists a comprehensive guide.},
  year = {2013}
}

@book{wick_2022_numerical,
  author = {Wick, Thomas},
  edition = {2},
  month = {01},
  publisher = {Leibniz Universität Hannover},
  title = {Numerical Methods for Partial Differential Equations},
  year = {2022}
}

@book{richter_2017_einfhrung,
  author = {Richter, Thomas and Wick, Thomas},
  month = {11},
  publisher = {Springer-Verlag},
  title = {Einführung in die Numerische Mathematik},
  year = {2017}
}

@book{davidjeffreygriffiths_2018_introduction,
  author = {David Jeffrey Griffiths and Schroeter, Darrell F and Cambridge University Press},
  publisher = {Cambridge University Press},
  title = {Introduction to quantum mechanics},
  year = {2018}
}

@book{farlow_2012_partial,
  author = {Farlow, Stanley J},
  month = {03},
  publisher = {Courier Corporation},
  title = {Partial Differential Equations for Scientists and Engineers},
  year = {2012}
}

@misc{hunt_2002_dr,
  author = {Hunt, Robert },
  title = {Dr Robert Hunt: Lecture Notes and Handouts},
  url = {https://www.damtp.cam.ac.uk/user/reh10/lectures/},
  urldate = {2023-03-22},
  year = {2002},
  organization = {www.damtp.cam.ac.uk}
}

@misc{ellingson_2018_515,
  author = {Ellingson, Steven W.},
  month = {12},
  title = {5.15: Poisson’s and Laplace’s Equations},
  url = {https://eng.libretexts.org/Bookshelves/Electrical_Engineering/Electro-Optics/Book3A_Electromagnetics_I_(Ellingson)/053A_Electrostatics/5.153A_PoissonE28099s_and_LaplaceE28099s_Equations},
  urldate = {2023-03-23},
  year = {2018},
  organization = {Engineering LibreTexts}
}

@misc{fitzpatrick_2014_poissons,
  author = {Fitzpatrick, RIchard},
  month = {06},
  title = {Poisson's Equation in Cylindrical Coordinates},
  url = {https://farside.ph.utexas.edu/teaching/jk1/Electromagnetism/node37.html#e2.182},
  urldate = {2023-03-23},
  year = {2014},
  organization = {farside.ph.utexas.edu}
}

@article{hughes_1971_solution,
  author = {Hughes, M.H.},
  month = {04},
  pages = {157-167},
  title = {Solution of poisson's equation in cylindrical coordinates},
  doi = {10.1016/0010-4655(71)90047-6},
  urldate = {2020-02-07},
  volume = {2},
  year = {1971},
  journal = {Computer Physics Communications}
}

@book{davidjeffreygriffiths_2018_introduction,
  author = {David Jeffrey Griffiths and Cambridge University Press},
  publisher = {Cambridge University Press},
  title = {Introduction to electrodynamics},
  year = {2018}
}

@book{grant_1990_electromagnetism,
  author = {Grant, I S and Phillips, W R},
  publisher = {John Wiley},
  title = {Electromagnetism},
  year = {1990}
}

@book{Mitchell1997,
   author = {Tom Michael Mitchell},
   note = {tes<br/>},
   title = {Machine Learning},
   year = {1997},
}

 @book{zocca_spacagna_slater_roelants_2017, address={Birmingham, UK}, title={Python Deep Learning}, ISBN={9781786460660}, publisher={Packt Publishing}, author={Zocca, Valentino and Spacagna, Gianmario and Slater, Daniel and Roelants, Peter}, year={2017}, month={Apr} }

 @misc{patel_2020, title={Convolution Neural Networks — a Beginner’s Guide}, url={https://towardsdatascience.com/convolution-neural-networks-a-beginners-guide-implementing-a-mnist-hand-written-digit-8aa60330d022}, journal={Medium}, publisher={Towards Data Science}, author={Patel, Krut}, year={2020}, month={Oct} }

@article{Lederer2021,
   abstract = {Activation functions shape the outputs of artificial neurons and, therefore, are integral parts of neural networks in general and deep learning in particular. Some activation functions, such as logistic and relu, have been used for many decades. But with deep learning becoming a mainstream research topic, new activation functions have mushroomed, leading to confusion in both theory and practice. This paper provides an analytic yet up-to-date overview of popular activation functions and their properties, which makes it a timely resource for anyone who studies or applies neural networks.},
   author = {Johannes Lederer},
   month = {1},
   title = {Activation Functions in Artificial Neural Networks: A Systematic Overview},
   url = {http://arxiv.org/abs/2101.09957},
   year = {2021},
}

@online{saha2018,
   author = {Sumit Saha},
   journal = {Towards Data Science},
   month = {12},
   title = {A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way},
   url = {https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53},
   year = {2018},
}

@article{oshea2015,
   abstract = {The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning.},
   author = {Keiron O'Shea and Ryan Nash},
   month = {11},
   title = {An Introduction to Convolutional Neural Networks},
   url = {http://arxiv.org/abs/1511.08458},
   year = {2015},
}

@book{Blackledge2006,
   author = {Jonathan M. Blackledge},
   city = {Chichester, West Sussex, England},
   edition = {2},
   publisher = {Horwood Publishing},
   title = {DIGITAL SIGNAL PROCESSING},
   year = {2006},
}

@book{Ford2015,
   author = {William Ford},
   edition = {1st},
   publisher = {Academic Press, Elsevier},
   title = {Numerical Linear Algebra with Applications Using MATLAB},
   year = {2015},
}

@book{chapra2015,
   abstract = {Seventh edition. "The seventh edition of Chapra and Canale's Numerical Methods for Engineers retains the instructional techniques that have made the text so successful. Numerous new or revised problems are drawn from actual engineering practice. The expanded breadth of engineering disciplines covered is especially evident in these exercises, which now cover such areas as biotechnology and biomedical engineering. Excellent new examples and case studies span all areas of engineering giving students a broad exposure to various fields in engineering." -- Provided by publisher. Part 1 -- Modeling, Computers, and Error Analysis -- 1) Mathematical Modeling and Engineering Problem Solving -- 2) Programming and Software -- 3) Approximations and Round-Off Errors -- 4) Truncation Errors and the Taylor Series -- Part 2 -- Roots of Equations -- 5) Bracketing Methods -- 6) Open Methods -- 7) Roots of Polynomials -- 8) Case Studies: Roots of Equations -- Part 3 -- Linear Algebraic Equations -- 9) Gauss Elimination -- 10) LU Decomposition and Matrix Inversion -- 11) Special Matrices and Gauss-Seidel -- 12) Case Studies: Linear Algebraic Equations -- Part 4 -- Optimization -- 13) One-Dimensional Unconstrained Optimization -- 14) Multidimensional Unconstrained Optimization -- 15) Constrained Optimization -- 16) Case Studies: Optimization -- Part 5 -- Curve Fitting -- 17) Least-Squares Regression -- 18) Interpolation -- 19) Fourier Approximation -- 20) Case Studies: Curve Fitting -- Part 6 -- Numerical Differentiation and Integration -- 21) Newton-Cotes Integration Formulas -- 22) Integration of Equations -- 23) Numerical Differentiation -- 24) Case Studies: Numerical Integration and Differentiation -- Part 7 -- Ordinary Differential Equations -- 25) Runge-Kutta Methods -- 26) Stiffness and Multistep Methods -- 27) Boundary-Value and Eigenvalue Problems -- 28) Case Studies: Ordinary Differential Equations -- Part 8 -- Partial Differential Equations -- 29) Finite Difference: Elliptic Equations -- 30) Finite Difference: Parabolic Equations -- 31) Finite-Element Method -- 32) Case Studies: Partial Differential Equations -- Appendix A -- The Fourier Series -- Appendix B -- Getting Started with Matlab -- Appendix C -- Getting Started with Mathcad -- Bibliography -- Index.},
   author = {Steven C. Chapra and Raymond P. Canale},
   city = {New York},
   edition = {7th},
   isbn = {9780073397924},
   publisher = {McGraw-Hill Education},
   title = {Numerical Methods for Engineers},
   year = {2015},
}

@book{zhang2020dive,
    title={Dive into Deep Learning},
    author={Aston Zhang and Zachary C. Lipton and Mu Li and Alexander J. Smola},
    note={\url{https://d2l.ai}},
    year={2020}
}

@article{lagaris1998,
   abstract = {We present a method to solve initial and boundary value problems using artificial neural networks. A trial solution of the differential equation is written as a sum of two parts. The first part satisfies the initial/boundary conditions and contains no adjustable parameters. The second part is constructed so as not to affect the initial/boundary conditions. This part involves a feedforward neural network containing adjustable parameters (the weights). Hence by construction the initial/boundary conditions are satisfied and the network is trained to satisfy the differential equation. The applicability of this approach ranges from single ordinary differential equations (ODE's), to systems of coupled ODE's and also to partial differential equations (PDE's). In this article, we illustrate the method by solving a variety of model problems and present comparisons with solutions obtained using the Galekrkin finite element method for several cases of partial differential equations. With the advent of neuroprocessors and digital signal processors the method becomes particularly interesting due to the expected essential gains in the execution speed. Index Terms-Collocation method, finite elements, neural networks , neuroprocessors, ordinary differential equations, partial differential equations.},
   author = {Isaac Elias Lagaris and Aristidis Likas and Dimitrios I Fotiadis},
   issue = {5},
   journal = {IEEE TRANSACTIONS ON NEURAL NETWORKS},
   title = {Artificial Neural Networks for Solving Ordinary and Partial Differential Equations},
   volume = {9},
   year = {1998},
}

@article{Smaoui2004,
   abstract = {The dynamics of two nonlinear partial differential equations (PDEs) known as the Kuramoto-Sivashinsky (K-S) equation and the two-dimensional Navier-Stokes (N-S) equations are analyzed using Karhunen-Loéve (K-L) decomposition and artificial neural networks (ANN). For the K-S equation, numerical simulations using a pseudospectral Galerkin method is presented at a bifurcation parameter α=17.75, where a dynamical behavior represented by a heteroclinic connection is obtained. We apply K-L decomposition on the numerical simulation data with the task of reducing the data into a set of data coefficients. Then we use ANN to model, and predict the data coefficients at a future time. It is found that training the neural networks with only the first data coefficient is enough to capture the underlying dynamics, and to predict for the other remaining data coefficients. As for the two-dimensional N-S equation, a quasiperiodic behavior represented in phase space by a torus is analyzed at Re=14.0. Applying the symmetry observed in the two-dimensional N-S equations on the quasiperiodic behavior, eight different tori were obtained. We show that by exploiting the symmetries of the equation and using K-L decomposition in conjunction with neural networks, a smart neural model is obtained. © 2004 Elsevier B.V. All rights reserved.},
   author = {Nejib Smaoui and Suad Al-Enezi},
   doi = {10.1016/j.cam.2003.12.045},
   issn = {03770427},
   issue = {1},
   journal = {Journal of Computational and Applied Mathematics},
   keywords = {Karhunen-Loeve decomposition,Neural networks,One-dimensional Kuramoto-Sivashinsky equation,Two-dimensional Navier-Stokes equations},
   month = {9},
   pages = {27-58},
   title = {Modelling the dynamics of nonlinear partial differential equations using neural networks},
   volume = {170},
   year = {2004},
}

@article{baymani2010,
   abstract = {In this paper a new method based on neural network has been developed for obtaining the solution of the Stokes problem. We transform the mixed Stokes problem into three independent Poisson problems which by solving them the solution of the Stokes problem is obtained. The results obtained by this method, has been compared with the existing numerical method and with the exact solution of the problem. It can be observed that the current new approximation has higher accuracy. The number of model parameters required is less than conventional methods. The proposed new method is illustrated by an example.},
   author = {Modjtaba Baymani and Asghar Kerayechian and Sohrab Effati},
   doi = {10.4236/am.2010.14037},
   issn = {2152-7385},
   issue = {04},
   journal = {Applied Mathematics},
   pages = {288-292},
   publisher = {Scientific Research Publishing, Inc,},
   title = {Artificial Neural Networks Approach for Solving Stokes Problem},
   volume = {01},
   year = {2010},
}

@article{Ozbay2021,
   abstract = {The Poisson equation is commonly encountered in engineering, for instance, in computational fluid dynamics (CFD) where it is needed to compute corrections to the pressure field to ensure the incompressibility of the velocity field. In the present work, we propose a novel fully convolutional neural network (CNN) architecture to infer the solution of the Poisson equation on a 2D Cartesian grid with different resolutions given the right-hand side term, arbitrary boundary conditions, and grid parameters. It provides unprecedented versatility for a CNN approach dealing with partial differential equations. The boundary conditions are handled using a novel approach by decomposing the original Poisson problem into a homogeneous Poisson problem plus four inhomogeneous Laplace subproblems. The model is trained using a novel loss function approximating the continuous norm between the prediction and the target. Even when predicting on grids denser than previously encountered, our model demonstrates encouraging capacity to reproduce the correct solution profile. The proposed model, which outperforms well-known neural network models, can be included in a CFD solver to help with solving the Poisson equation. Analytical test cases indicate that our CNN architecture is capable of predicting the correct solution of a Poisson problem with mean percentage errors below 10\%, an improvement by comparison to the first step of conventional iterative methods. Predictions from our model, used as the initial guess to iterative algorithms like Multigrid, can reduce the root mean square error after a single iteration by more than 90\% compared to a zero initial guess.},
   author = {Ali Girayhan Ozbay and Arash Hamzehloo and Sylvain Laizet and Panagiotis Tzirakis and Georgios Rizos and Bjorn Schuller},
   doi = {10.1017/dce.2021.7},
   issn = {26326736},
   issue = {6},
   journal = {Data-Centric Engineering},
   keywords = {Convolutional neural network,Poisson equation,partial differential equations},
   month = {6},
   publisher = {Cambridge University Press},
   title = {Poisson CNN: Convolutional neural networks for the solution of the Poisson equation on a Cartesian mesh},
   volume = {2},
   year = {2021},
}

@televisionbroadcast{laurencemoroney2022,
   author = {Laurence Moroney},
   publisher = {Coursera},
   title = {Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning},
   year = {2022},
}

@book{denny2015,
   author = {Denny Britz},
   month = {9},
   title = {Implementing a Neural Network from Scratch in Python},
   url = {https://dennybritz.com/posts/wildml/implementing-a-neural-network-from-scratch/#learning-the-parameters},
   year = {2015},
}

@article{Shiferaw2013,
   author = {Alemayehu Shiferaw and R. C. Mittal},
   doi = {10.4236/ajcm.2013.34045},
   issn = {2161-1203},
   issue = {04},
   journal = {American Journal of Computational Mathematics},
   pages = {356-361},
   title = {Fast Finite Difference Solutions of the Three Dimensional Poisson’s Equation in Cylindrical Coordinates},
   volume = {03},
   year = {2013},
}

@book{Bottoni2022,
   author = {Maurizio Bottoni},
   city = {Cham},
   doi = {10.1007/978-3-030-79717-1},
   isbn = {978-3-030-79716-4},
   publisher = {Springer International Publishing},
   title = {Physical Modeling and Computational Techniques for Thermal and Fluid-dynamics},
   year = {2022},
}

@article{Brio2010,
   author = {M. Brio and G.M. Webb and A.R. Zakharian},
   doi = {10.1016/S0076-5392(10)21309-7},
   journal = {Mathematics in Science and Engineering},
   pages = {145-174},
   title = {Numerical Boundary Conditions},
   volume = {213},
   year = {2010},
}

@book{zwilinger2022,
   author = {Daniel Zwilinger and Vladimir Dobrushkin},
   edition = {4th},
   city = {Boca Raton},
   institution = {CRC Press},
   title = {Handbook of Differential Equations},
   year = {2022},
}

@misc{waletPartial,
        author = {Niels Walet},
	note = {[Online; accessed 2023-06-19]},
	year = {2022},
	month = {jul 5},
	publisher = {University of Manchester},
	title = {Partial Differential Equations (Walet)},
}

@misc{Li_Li_Gao, title={ Stanford CS231n course: Convolutional neural networks for visual recognition.}, year={2023}, journal={Stanford University}, author={Li, Fei-Fei and Li, Yunzhu and Gao, Ruohan}} 

@book{aurélien_géron_2022, title={Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow}, ISBN={9781098122478}, publisher={“O’Reilly Media, Inc.”}, author={Aurélien Géron}, year={2022}, month={Oct} }

 @book{goodfellow_bengio_courville_2016, address={Cambridge, Massachusetts}, edition={2}, title={Deep Learning}, ISBN={9780262035613}, publisher={The Mit Press}, author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron}, year={2016} }

 @book{elgendy_2020, title={Deep Learning for Vision Systems}, ISBN={9781617296192}, publisher={Shelter Island, Ny Manning Publications Co}, author={Elgendy, Mohamed}, year={2020} }

 @book{szeliski_2011, address={London}, title={Computer Vision : Algorithms and Applications}, ISBN={9781848829343}, publisher={Springer}, author={Szeliski, Richard}, year={2011} }

@book{zhang2023dive,
    title={Dive into Deep Learning},
    author={Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
    publisher={Cambridge University Press},
    note={\url{https://D2L.ai}},
    year={2023}
}

 @misc{brownlee_2019, title={Loss and Loss Functions for Training Deep Learning Neural Networks}, url={https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/}, journal={Machine Learning Mastery}, author={Brownlee, Jason}, year={2019}, month={May} }

 @misc{shankar_2022, title={Understanding Loss Function in Deep Learning}, url={https://www.analyticsvidhya.com/blog/2022/06/understanding-loss-function-in-deep-learning/}, journal={Analytics Vidhya}, author={Shankar}, year={2022}, month={Jun} }

@article{DEMYTTENAERE201638,
title = {Mean Absolute Percentage Error for regression models},
journal = {Neurocomputing},
volume = {192},
pages = {38-48},
year = {2016},
note = {Advances in artificial neural networks, machine learning and computational intelligence},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.12.114},
url = {https://www.sciencedirect.com/science/article/pii/S0925231216003325},
author = {Arnaud {de Myttenaere} and Boris Golden and Bénédicte {Le Grand} and Fabrice Rossi},
keywords = {Mean Absolute Percentage Error, Empirical Risk Minimization, Consistency, Optimization, Kernel regression},
abstract = {We study in this paper the consequences of using the Mean Absolute Percentage Error (MAPE) as a measure of quality for regression models. We prove the existence of an optimal MAPE model and we show the universal consistency of Empirical Risk Minimization based on the MAPE. We also show that finding the best model under the MAPE is equivalent to doing weighted Mean Absolute Error (MAE) regression, and we apply this weighting strategy to kernel regression. The behavior of the MAPE kernel regression is illustrated on simulated data.}
}

@article{chetlur2014cudnn,
  title={cudnn: Efficient primitives for deep learning},
  author={Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
  journal={arXiv preprint arXiv:1410.0759},
  year={2014}
}

@INPROCEEDINGS{1992SPIE.1709..257Z,
       author = {{Zhang}, Wei and {Hasegawa}, Akira and {Matoba}, Osamu and {Itoh}, Kazuyoshi and {Ichioka}, Yoshiki and {Doi}, Kunio},
        title = "{Shift-invariant neural network for image processing: learning and generalization}",
    booktitle = {Applications of Artificial Neural Networks III},
         year = 1992,
       editor = {{Rogers}, Steven K.},
       series = {Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series},
       volume = {1709},
        month = sep,
        pages = {257-268},
          doi = {10.1117/12.140004},
       adsurl = {https://ui.adsabs.harvard.edu/abs/1992SPIE.1709..257Z},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{DBLP:journals/corr/abs-2109-13076,
  author       = {Lionel Cheng and
                  Ekhi Ajuria Illarramendi and
                  Guillaume Bogopolsky and
                  Michael Bauerheim and
                  B{\'{e}}n{\'{e}}dicte Cuenot},
  title        = {Using neural networks to solve the 2D Poisson equation for electric
                  field computation in plasma fluid simulations},
  journal      = {CoRR},
  volume       = {abs/2109.13076},
  year         = {2021},
  url          = {https://arxiv.org/abs/2109.13076},
  eprinttype    = {arXiv},
  eprint       = {2109.13076},
  timestamp    = {Mon, 04 Oct 2021 17:22:25 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2109-13076.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/RonnebergerFB15,
  author       = {Olaf Ronneberger and
                  Philipp Fischer and
                  Thomas Brox},
  title        = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  journal      = {CoRR},
  volume       = {abs/1505.04597},
  year         = {2015},
  url          = {http://arxiv.org/abs/1505.04597},
  eprinttype    = {arXiv},
  eprint       = {1505.04597},
  timestamp    = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RonnebergerFB15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/LongSD14,
  author       = {Jonathan Long and
                  Evan Shelhamer and
                  Trevor Darrell},
  title        = {Fully Convolutional Networks for Semantic Segmentation},
  journal      = {CoRR},
  volume       = {abs/1411.4038},
  year         = {2014},
  url          = {http://arxiv.org/abs/1411.4038},
  eprinttype    = {arXiv},
  eprint       = {1411.4038},
  timestamp    = {Mon, 13 Aug 2018 16:48:17 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/LongSD14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

 @book{brownlee_2016, edition={1.1}, title={Master Machine Learning Algorithms}, publisher={Machine Learning Mastery}, author={Brownlee, Jason}, year={2016}, month={Mar} }

 @phdthesis{cohl_1999, address={LSU Historical Dissertations and Theses}, title={On the Numerical Solution of the Cylindrical Poisson Equation for Isolated Self -Gravitating Systems}, author={Cohl, Howard Saul}, year={1999} }

 @misc{moroney_2022, title={DeepLearning.AI TensorFlow Developer}, url={https://www.coursera.org/professional-certificates/tensorflow-in-practice}, journal={Coursera}, publisher={Coursera}, author={Moroney, Laurence}, year={2022} }

 @article{norberg_1995, title={Differential Equations for Moments of Present Values in Life Insurance}, volume={17}, DOI={https://doi.org/10.1016/0167-6687(95)00019-o}, number={2}, journal={Insurance: Mathematics and Economics}, author={Norberg, Ragnar}, year={1995}, month={Oct}, pages={171–180} }

 @article{culshaw_ruan_2000, title={A delay-differential Equation Model of HIV Infection of CD4+ T-cells}, volume={165}, DOI={https://doi.org/10.1016/s0025-5564(00)00006-7}, number={1}, journal={Mathematical Biosciences}, author={Culshaw, Rebecca V. and Ruan, Shigui}, year={2000}, month={May}, pages={27–39} }

 @article{kumar_yadav_2011, title={Multilayer Perceptrons and Radial Basis Function Neural Network Methods for the Solution of Differential equations: a Survey}, volume={62}, DOI={https://doi.org/10.1016/j.camwa.2011.09.028}, number={10}, journal={Computers & Mathematics with Applications}, author={Kumar, Manoj and Yadav, Neha}, year={2011}, month={Nov}, pages={3796–3811} }

 @article{braga_miranda_2019, title={Particle-in-cell Numerical Simulation of the PHall-IIc Hall Thruster}, volume={1365}, DOI={https://doi.org/10.1088/1742-6596/1365/1/012013}, number={1}, journal={Journal of Physics: Conference Series}, author={Braga, Leonardo L. and Miranda, Rodrigo A.}, year={2019}, month={Oct}, pages={012013} }

 @article{mcculloch_pitts_1943, title={A Logical Calculus of the Ideas Immanent in Nervous Activity}, volume={5}, url={https://link.springer.com/article/10.1007/BF02478259}, DOI={https://doi.org/10.1007/bf02478259}, number={4}, journal={The Bulletin of Mathematical Biophysics}, author={McCulloch, Warren S. and Pitts, Walter}, year={1943}, month={Dec}, pages={115–133} }

 @article{morris_1999, title={D.O. Hebb: the Organization of Behavior, Wiley: New York; 1949}, volume={50}, DOI={https://doi.org/10.1016/s0361-9230(99)00182-3}, number={5-6}, journal={Brain Research Bulletin}, author={Morris, R.G.M}, year={1999}, month={Nov}, pages={437} }

 @article{rosenblatt_1958, title={The perceptron: a Probabilistic Model for Information Storage and Organization in the brain.}, volume={65}, DOI={https://doi.org/10.1037/h0042519}, number={6}, journal={Psychological Review}, author={Rosenblatt, Frank}, year={1958}, pages={386–408} }

 @article{rumelhart_hinton_williams_1986, title={Learning Representations by back-propagating Errors}, volume={323}, url={https://www.nature.com/articles/323533a0}, DOI={https://doi.org/10.1038/323533a0}, number={6088}, journal={Nature}, author={Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.}, year={1986}, month={Oct}, pages={533–536} }

 @article{hinton_osindero_teh_2006, title={A Fast Learning Algorithm for Deep Belief Nets}, volume={18}, DOI={https://doi.org/10.1162/neco.2006.18.7.1527}, number={7}, journal={Neural Computation}, author={Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye}, year={2006}, month={Jul}, pages={1527–1554} }

@inproceedings{NIPS2006_5da713a6,
 author = {Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {B. Sch\"{o}lkopf and J. Platt and T. Hoffman},
 pages = {},
 publisher = {MIT Press},
 title = {Greedy Layer-Wise Training of Deep Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2006/file/5da713a690c067105aeb2fae32403405-Paper.pdf},
 volume = {19},
 year = {2006}
}

 @article{von_melchner_pallas_sur_2000, title={Visual Behaviour Mediated by Retinal Projections Directed to the Auditory Pathway}, volume={404}, url={https://www.nature.com/articles/35009102}, DOI={https://doi.org/10.1038/35009102}, number={6780}, journal={Nature}, author={von Melchner, Laurie and Pallas, Sarah L. and Sur, Mriganka}, year={2000}, month={Apr}, pages={871–876} }

 @article{fukushima_1980, title={Neocognitron: a self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position}, volume={36}, DOI={https://doi.org/10.1007/bf00344251}, number={4}, journal={Biological Cybernetics}, author={Fukushima, Kunihiko}, year={1980}, month={Apr}, pages={193–202} }

@ARTICLE{726791,
  author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324},
  doi={10.1109/5.726791}}

 @article{lecun_kavukcuoglu_farabet_2010, title={Convolutional Networks and Applications in Vision}, ISBN={9781424453085}, DOI={https://doi.org/10.1109/iscas.2010.5537907}, journal={Proceedings of 2010 IEEE International Symposium on Circuits and Systems}, author={LeCun, Yann and Kavukcuoglu, Koray and Farabet, Clement}, year={2010}, month={May} }

 @article{lee_kang_1990, title={Neural Algorithm for Solving Differential Equations}, volume={91}, DOI={https://doi.org/10.1016/0021-9991(90)90007-n}, number={1}, journal={Journal of Computational Physics}, author={Lee, Hyuk and Kang, In Seok}, year={1990}, month={Nov}, pages={110–131} }

@misc{cheng2021using,
      title={Using neural networks to solve the 2D Poisson equation for electric field computation in plasma fluid simulations}, 
      author={Lionel Cheng and Ekhi Ajuria Illarramendi and Guillaume Bogopolsky and Michael Bauerheim and Benedicte Cuenot},
      year={2021},
      eprint={2109.13076},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{DBLP:journals/corr/abs-1711-10561,
  author       = {Maziar Raissi and
                  Paris Perdikaris and
                  George E. Karniadakis},
  title        = {Physics Informed Deep Learning (Part {I):} Data-driven Solutions of
                  Nonlinear Partial Differential Equations},
  journal      = {CoRR},
  volume       = {abs/1711.10561},
  year         = {2017},
  url          = {http://arxiv.org/abs/1711.10561},
  eprinttype    = {arXiv},
  eprint       = {1711.10561},
  timestamp    = {Mon, 13 Aug 2018 16:47:03 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1711-10561.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

 @article{cheng_illarramendi_bauerheim_cuenot_2021, title={PlasmaNet: a Framework to Study and Solve Elliptic Differential Equations Using Neural Networks in Plasma Fluid Simulations}, author={Cheng, Lionel and Illarramendi, Ekhi Ajuria and Bauerheim, Michaël and Cuenot, Bénédicte}, year={2021}, month={Dec} }

 @book{lubos_brieda_2019, title={Plasma Simulations by Example}, ISBN={9780429801051}, publisher={CRC Press}, author={Lubos Brieda}, year={2019}, month={Dec} }

 @misc{google_2022, title={Normalization}, url={https://developers.google.com/machine-learning/data-prep/transform/normalization}, journal={Google Developers}, author={Google}, year={2022}, month={Jul} }

@misc{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

 @misc{jason_brownlee_2017, title={What Is the Difference between Test and Validation Datasets?}, url={https://machinelearningmastery.com/difference-test-validation-datasets/}, journal={Machine Learning Mastery}, author={Jason Brownlee}, year={2017}, month={Jul} }

@article{israel1992determining,
  title={Determining sample size},
  author={Israel, Glenn D},
  year={1992},
  publisher={University of Florida Cooperative Extension Service, Institute of Food and~…}
}

 @article{f_taccogna_longo_capitelli_schneider_2005, title={Plasma Flow in a Hall Thruster}, volume={12}, DOI={https://doi.org/10.1063/1.1862630}, number={4}, journal={Physics of Plasmas}, publisher={American Institute of Physics}, author={F. Taccogna and Longo, S and Capitelli, M and Schneider, R}, year={2005}, month={Apr}, pages={043502–043502} }

 @article{boeuf_2017, title={Tutorial: Physics and Modeling of Hall Thrusters}, volume={121}, DOI={https://doi.org/10.1063/1.4972269}, number={1}, journal={Journal of Applied Physics}, author={Boeuf, Jean-Pierre}, year={2017}, month={Jan}, pages={011101} }

@misc{alom2018recurrent,
      title={Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net) for Medical Image Segmentation}, 
      author={Md Zahangir Alom and Mahmudul Hasan and Chris Yakopcic and Tarek M. Taha and Vijayan K. Asari},
      year={2018},
      eprint={1802.06955},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

 @article{siddique_paheding_elkin_devabhaktuni_2021, title={U-Net and Its Variants for Medical Image Segmentation: a Review of Theory and Applications}, volume={1}, url={https://arxiv.org/pdf/2011.01118.pdf}, DOI={https://doi.org/10.1109/access.2021.3086020}, number={9}, journal={IEEE Access}, author={Siddique, Nahian and Paheding, Sidike and Elkin, Colin P. and Devabhaktuni, Vijay}, year={2021}, pages={82031–82057} }

 @book{brownlee_2019a, edition={1.3}, title={Better Deep Learning: Train Faster, Reduce Overfitting, and Make Better Prediction}, author={Brownlee, Jason}, year={2019} }

 @misc{suki_lau_2017, title={Learning Rate Schedules and Adaptive Learning Rate Methods for Deep Learning}, url={https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1}, journal={Medium}, publisher={Towards Data Science}, author={Suki Lau}, year={2017}, month={Jul} }

 @misc{roberts_2023b, title={Mean Absolute Percentage Error (MAPE): What You Need to Know}, url={https://arize.com/blog-course/mean-absolute-percentage-error-mape-what-you-need-to-know/}, journal={Arize AI}, author={Roberts, Amber}, year={2023}, month={Feb} }

